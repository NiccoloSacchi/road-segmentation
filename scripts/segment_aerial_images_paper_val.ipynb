{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# keras functions\n",
    "from keras import callbacks\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# our libraries\n",
    "from preprocessing import *\n",
    "\n",
    "from cnn_models import *\n",
    "from evaluate import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "n = 10\n",
    "batch_idx = 0\n",
    "\n",
    "imgs, gt_imgs = load_images_range(batch_idx*n,(batch_idx+1)*n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Convert the data to the correct format\n",
    "We reshape each input to fulfill the requirements of the tensorflow library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set predict_patch_width in accordance to the model: the model is classifying \n",
    "# patch-wise, patches of size predict_patch_width x predict_patch_width\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.5\n",
    "\n",
    "train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape, train.Y.shape, test.X.shape, test.Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model\n",
    "Choose one of the models you defined and the compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Fit the model on the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#building a datagenerator\n",
    "import keras as ks\n",
    "datagen = ks.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0,\n",
    "    fill_mode='wrap',\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=True,\n",
    "    rescale=None)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(train.X)\n",
    "\n",
    "generator = datagen.flow(train.X,train.Y,batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#checking that the flow is working\n",
    "batches = datagen.flow(train.X,train.Y,batch_size=32)\n",
    "x_batch, y_batch = next(batches)\n",
    "\n",
    "\n",
    "for i in range (0,1):\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "filepath = \"..\\\\models\\\\07.12-0.85.hdf5\"\n",
    "model = ks.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = \"..\\\\models\\\\\" + str('{0:%Y-%m-%d_%H%M%S}'.format(datetime.now()))+\"_best-weights.hdf5\" # -{epoch:03d}-{loss:.4f}-{acc:.4f}\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 1\n",
    "steps_per_epoch = 1\n",
    "# here's a more \"manual\" example\n",
    "for e in range(num_epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in generator:\n",
    "        model.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= steps_per_epoch:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = \"..\\\\models\\\\\" + str('{0:%Y-%m-%d_%H%M%S}'.format(datetime.now()))+\"_best-weights.hdf5\" # -{epoch:03d}-{loss:.4f}-{acc:.4f}\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#this loads 10 images, uses the first 5 as train and the other as tests,\n",
    "#trains the model on 20 epochs then loads 10 more images and repeats the process\n",
    "#the whole thing is reapeated 10 times so the model is sequentially trained on different images\n",
    "\n",
    "n = 10\n",
    "half = 5\n",
    "num_batches = 9\n",
    "predict_patch_width = 8\n",
    "test_ratio = 0.5\n",
    "num_epoch = 20 #no improvement afterwards\n",
    "num_rounds = 10\n",
    "\n",
    "for round_idx in range(num_rounds):\n",
    "    for batch_idx in range(num_batches):\n",
    "        start =batch_idx*n + 5*(round_idx%2)\n",
    "        end = start + n\n",
    "        #the testing set of iteration i is the training set of iteration i+1\n",
    "        imgs, gt_imgs = load_images_range(start,end)\n",
    "        X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "        train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "\n",
    "        hist = model.fit(\n",
    "            train.X, train.Y, \n",
    "            batch_size = 32, \n",
    "            epochs = num_epoch, \n",
    "            verbose = 0, \n",
    "            validation_data = (test.X, test.Y), \n",
    "            callbacks = callbacks_list\n",
    "        )\n",
    "\n",
    "\n",
    "print('iteration ',batch_idx)\n",
    "set_ = train\n",
    "evaluate_model(model, set_.X, set_.Y)\n",
    "set_ = test\n",
    "evaluate_model(model, set_.X, set_.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# either validation_data=(test.X, test.Y) or validation_split=0.2\n",
    "num_epoch = 1\n",
    "num_steps = 1\n",
    "hist = model.fit_generator(\n",
    "    generator, \n",
    "    steps_per_epoch =num_steps,\n",
    "    epochs = num_epoch, \n",
    "    verbose = 1,\n",
    "    validation_data = datagen.flow(test.X, test.Y, batch_size=32), \n",
    "    validation_steps = num_steps,\n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = test.X[0]\n",
    "layer_num = 3\n",
    "\n",
    "show_layer_output(model, image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "set_ = test\n",
    "\n",
    "evaluate_model(model, set_.X, set_.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "img = train.X[2][:, :]\n",
    "\n",
    "display_prediction(model, img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Saving and loading model and weights\n",
    "# from keras.models import model_from_json\n",
    "# from keras.models import load_model\n",
    "\n",
    "# # serialize model to JSON\n",
    "# model_json = model.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# # serialize weights to HDF5\n",
    "# model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "\n",
    "# # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    "\n",
    "# model.save('model.hdf5')\n",
    "# loaded_model=load_model('model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
