{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os,sys\n",
    "from PIL import Image\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "root_dir = \"../dataset/training/\"\n",
    "\n",
    "image_dir = root_dir + \"images/\"\n",
    "files = os.listdir(image_dir)\n",
    "n = min(20, len(files)) # Load maximum 20 images\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "imgs = [load_image(image_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "gt_dir = root_dir + \"groundtruth/\"\n",
    "print(\"Loading \" + str(n) + \" images\")\n",
    "gt_imgs = [load_image(gt_dir + files[i]) for i in range(n)]\n",
    "print(files[0])\n",
    "\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show first image and its groundtruth image\n",
    "# cimg = concatenate_images(imgs[1], gt_imgs[1])\n",
    "# fig1 = plt.figure(figsize=(20, 10))\n",
    "# plt.imshow(cimg, cmap='Greys_r', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate the input and extract the outputs.\n",
    "From each image extract the inputs (patches) and generate a list of features for each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 # number of images\n",
    "X = imgs_to_inputs(imgs[:n])\n",
    "Y = imgs_to_outputs(gt_imgs[:n])\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just check the **output** has been generated correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature statistics\n",
    "Y0 = np.where(Y==0)[0]\n",
    "Y1 = np.where(Y==1)[0]\n",
    "print(str(len(Y1)) + ' inputs are classified as background (0)')\n",
    "print(str(len(Y0)) + ' inputs are classified as road (1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix:')\n",
    "confusion_matrix = pd.DataFrame(\n",
    "    data = [['True Negative (TN)', 'False Negative (FN)'], ['False Positive (FP)', 'True Positive (TP)']],\n",
    "    index = pd.MultiIndex(\n",
    "        levels=[['predicted (Z)'], ['0', '1']],\n",
    "        labels=[[0, 0], [0, 1]]),\n",
    "    columns = pd.MultiIndex(\n",
    "        levels=[['actual (Y)'], ['0 (background)', '1 (road)']],\n",
    "        labels=[[0, 0], [0, 1]]),\n",
    ")\n",
    "display(confusion_matrix)\n",
    "print('TN + FN + FP + TP = number of predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5, class_weight=\"balanced\")\n",
    "# train\n",
    "logreg.fit(X, Y)\n",
    "# predict\n",
    "Z = logreg.predict(X)\n",
    "\n",
    "FNR = np.sum((Z == 0) & (Y == 1)) / float(len(Z))\n",
    "TNR = np.sum((Z == 0) & (Y == 0)) / float(len(Z))\n",
    "confusion_matrix.iloc[0, 0], confusion_matrix.iloc[0, 1] = TNR, FNR\n",
    "\n",
    "FPR = np.sum((Z == 1) & (Y == 0)) / float(len(Z))\n",
    "TPR = np.sum((Z == 1) & (Y == 1)) / float(len(Z))\n",
    "confusion_matrix.iloc[1, 0], confusion_matrix.iloc[1, 1] = FPR, TPR\n",
    "\n",
    "# print('True positive rate = ' + str(TPR) + ' (#correctly predicted road patches / #predicted road patches)')\n",
    "print('Ratio of overall correct predictions: ' + str(np.sum(Z==Y)/float(len(Y))))\n",
    "display(confusion_matrix)\n",
    "print('Lot of non road patches are classified as road')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_img = imgs[13]\n",
    "\n",
    "Xi = img_to_inputs(validation_img)\n",
    "Zi = logreg.predict(Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction as an image\n",
    "fig1 = plt.figure(figsize=(10, 10)) # create a figure with the default size \n",
    "\n",
    "w, h = 400, 400\n",
    "predicted_im = label_to_img(w, h, patch_size, patch_size, Zi)\n",
    "# cimg = concatenate_images(imgs[img_idx], predicted_im)\n",
    "# plt.imshow(cimg, cmap='Greys_r', vmin=0, vmax=1)\n",
    "\n",
    "new_img = make_img_overlay(validation_img, predicted_im)\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
