{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import 'Sequential' is a linear stack of neural network layers. Will be used to build the feed-forward CNN\n",
    "from keras.models import Sequential \n",
    "# import the \"core\" layers from Keras (these are the most common layers)\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# import the convolutional layers that will help us efficiently train on image data\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# these utilities will help us transform our data\n",
    "from keras.utils import np_utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Keras tutorial](https://elitedatascience.com/keras-tutorial-deep-learning-in-python) on mnist dataset\n",
    "**N.B. I used tensorflow not theano as backend.** The only difference is in the shape that is (28, 28, 1) in tensorflow and (1, 28, 28) in theano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# images are 28x28 pixels\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just show an image\n",
    "plt.imshow(X_train[0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocess the input\n",
    "- You must explicitly declare a dimension for the depth. For example, a full-color image with all 3 RGB channels will have a depth of 3, while our images have depth of 1. We want to transform our dataset from having shape (n, width, height) to (n, width, height, depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert our data type to float32 and normalize our data values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Preprocess class labels\n",
    "We want 10 different classes, one for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define model architecture\n",
    "Let's start by declaring a sequential model format. Each layer has an input shape and an output shape. The input shape is automatically set as the output shape from the previous layer but we need to declare the input shape of the first layer and the output shape of the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 32 convolution filters\n",
    "# 3 rows in convolution kernel\n",
    "# 3 columns in convolution kernel\n",
    "# (1,28,28) is the shape of one input\n",
    "# strides=(1, 1) by default (step size?)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "# MaxPooling2D is a way to reduce the number of parameters in our model by sliding \n",
    "# a 2x2 pooling filter across the previous layer and taking the max of the 4 values \n",
    "# in the 2x2 filter.\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25)) # a method for regularizing our model in order to prevent overfitting.\n",
    "\n",
    "# a convolutional neural network always ends with a fully connected layer followe by the ouput\n",
    "# layer\n",
    "# first flatten the weights of the convolution\n",
    "model.add(Flatten())\n",
    "# 128 = output size of the dense layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 10 = output size of the output dense layer (we have 10 classes!)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More about 32, (3, 3)**: 32 is the number of filters that scan the image on a window 3Ã—3 pixels. Why 32 filters? We stack 32 of these filters to allow more complexity in the model, i.e. tey will learn different patterns during training.\n",
    " \n",
    "Read more about [dropout](https://www.quora.com/How-does-the-dropout-method-work-in-deep-learning-And-why-is-it-claimed-to-be-an-effective-trick-to-improve-your-network). Dropout(25) is a layer that drops 25% of its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compile the model\n",
    "When we compile the model, we declare the loss function and the optimizer (SGD, Adam, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [loss functions](https://keras.io/losses/) and [optimizers](https://keras.io/optimizers/) options in keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Fit the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have to declare the batch size and number of epochs to train for\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a variety of [callbacks](https://keras.io/callbacks/) to set early-stopping rules, save model weights along the way, or log the history of each training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test[:1])\n",
    "print(\"Prediction: \", np.argmax(prediction))\n",
    "plt.imshow(X_test[0].reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at some [example models in keras](https://github.com/fchollet/keras/tree/master/examples)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
