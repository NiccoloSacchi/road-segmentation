{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flow:\n",
    "1. load, reshape and split in test and train all the images\n",
    "2. instantiate a cnn model \n",
    "3. run the model on train and test data to verify how many epochs are more or less needed to get a nice model\n",
    "4. use that number of epochs to run cross validation (pass the whole 'set_' of images to the cross validation). Repeat from 2 with another model and compare.\n",
    "\n",
    "\n",
    "- If you notice that you hardly overfit maybe remove/decrease the dropout layers (e.g. from 0.25 to 0.15)\n",
    "- Try building a model that predicts directly 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import *\n",
    "from cnn_models import *\n",
    "from datetime import datetime\n",
    "from evaluate import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "n = 4\n",
    "\n",
    "imgs, gt_imgs = load_images(n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Reshape the data\n",
    "We reshape each input to fulfill our cnn inputs and output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! set predict_patch_width in accordance to the model you are using !!!\n",
    "# the shape of the output of the model depends on the strides parameters \n",
    "# (if a layer has stride=2 then each ouput's side is half of the input'side).\n",
    "# predict_patch_width must be equal to the total reduction of the model, e.g.\n",
    "# if the model has three layer with stride=2 => the input of the model is \n",
    "# reduced by a factor of 2*2*2=8, i.e. the ouptut will be patch-wise with \n",
    "# patches 8x8 pixels.\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "\n",
    "set_ = SimpleNamespace()\n",
    "set_.X = X\n",
    "set_.Y = Y\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.25\n",
    "\n",
    "train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape, train.Y.shape, test.X.shape, test.Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model or load a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose one of the models you defined (with model_n) and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an unique name for the model (so to avoid overwriting previous models)\n",
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H:%M:%S}'.format(datetime.now()))\n",
    "model_path = \"models/\"+folder_name\n",
    "model = CnnModel(model_n=0, model_path=model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otherwise load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the folder\n",
    "folder_name = \"model_2017-12-11_11:51:54\"\n",
    "model_path = \"models/\"+folder_name\n",
    "model = CnnModel(model_path=model_path)\n",
    "model.load() # load the model and its weights\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Train the model on the train data while validating it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a batch size which is a factor of train.shape[0] so that all the batches are fo the same size\n",
    "num_epochs=1\n",
    "batch_size=3\n",
    "_ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Run cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.cross_validation(set_, batch_size=batch_size, num_epochs=num_epochs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histories of the cross validation\n",
    "plot_history(result[\"history_mean\"]) \n",
    "# history of the folds (check if there is a worst case)\n",
    "# plot_history(result[\"histories\"][0]) \n",
    "# plot_history(result[\"histories\"][1]) \n",
    "# plot_history(result[\"histories\"][2]) \n",
    "# plot_history(result[\"histories\"][3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epochs=20 # plot only the last n epochs\n",
    "model.plot_history(last_epochs=last_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all the layers \n",
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = test.X[0]\n",
    "layer_num = 8\n",
    "\n",
    "model.show_layer_output(image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "set_ = train\n",
    "\n",
    "model.evaluate_model(set_.X, set_.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "img = test.X[0][:, :]\n",
    "\n",
    "model.display_prediction(img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "debugger = Pdb()\n",
    "debugger.set_trace() # put this line as a breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1, gen2 = image_generators(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models import batches_generator\n",
    "j = 0\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for x, y in batches_generator(X[:4], Y[:4], batch_size = 4):\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "    x_batches.append(x)\n",
    "    y_batches.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_batches).shape, np.array(y_batches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "if i >= x_batches[0].shape[0]:\n",
    "    i = 0\n",
    "    b += 1\n",
    "print(\"Batch\", str(b) + \". Image\", i)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches((20, 10))\n",
    "axs[0].imshow(x_batches[b][i], cmap='gray')\n",
    "axs[1].imshow(y_batches[b][i][:, :, 1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
