{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flow:\n",
    "1. load, reshape and split in test and train all the images\n",
    "2. instantiate a cnn model \n",
    "3. run the model on train and test data to verify how many epochs are more or less needed to get a nice model\n",
    "4. use that number of epochs to run cross validation (pass the whole 'set_' of images to the cross validation). Repeat from 2 with another model and compare.\n",
    "\n",
    "\n",
    "- If you notice that you hardly overfit maybe remove/decrease the dropout layers (e.g. from 0.25 to 0.15)\n",
    "- Try building a model that predicts directly 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import *\n",
    "from cnn_models import *\n",
    "from datetime import datetime\n",
    "from evaluate import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((400, 400, 3), (400, 400))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loaded a set of images\n",
    "n = 2\n",
    "\n",
    "imgs, gt_imgs = load_images(n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Reshape the data\n",
    "We reshape each input to fulfill our cnn inputs and output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 400, 400, 3), (2, 50, 50))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!! set predict_patch_width in accordance to the model you are using !!!\n",
    "# the shape of the output of the model depends on the strides parameters \n",
    "# (if a layer has stride=2 then each ouput's side is half of the input'side).\n",
    "# predict_patch_width must be equal to the total reduction of the model, e.g.\n",
    "# if the model has three layer with stride=2 => the input of the model is \n",
    "# reduced by a factor of 2*2*2=8, i.e. the ouptut will be patch-wise with \n",
    "# patches 8x8 pixels.\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "\n",
    "set_ = SimpleNamespace()\n",
    "set_.X = X\n",
    "set_.Y = Y\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.25\n",
    "\n",
    "train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape, train.Y.shape, test.X.shape, test.Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model or load a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose one of the models you defined (with model_n) and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate an unique name for the model (so to avoid overwriting previous models)\n",
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H:%M:%S}'.format(datetime.now()))\n",
    "model_path = \"models/\"+folder_name\n",
    "model = CnnModel(model_n=0, model_path=model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otherwise load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the folder\n",
    "folder_name = \"model_2017-12-14_194132\"\n",
    "model_path = \"../models/\"+folder_name\n",
    "model = CnnModel(model_path=model_path)\n",
    "model.load() # load the model and its weights\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Train the model on the train data while validating it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass a batch size which is a factor of train.shape[0] so that all the batches are fo the same size\n",
    "num_epochs=1\n",
    "batch_size=3\n",
    "_ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Run cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.cross_validation(set_, batch_size=batch_size, num_epochs=num_epochs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the histories of the cross validation\n",
    "plot_history(result[\"history_mean\"]) \n",
    "# history of the folds (check if there is a worst case)\n",
    "# plot_history(result[\"histories\"][0]) \n",
    "# plot_history(result[\"histories\"][1]) \n",
    "# plot_history(result[\"histories\"][2]) \n",
    "# plot_history(result[\"histories\"][3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epochs=1000 # plot only the last n epochs\n",
    "model.plot_history(last_epochs=last_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all the layers \n",
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = set_.X[0]\n",
    "layer_num = 1\n",
    "\n",
    "model.show_layer_output(image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "set_ = set_\n",
    "\n",
    "model.evaluate_model(set_.X, set_.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "img = test.X[0][:, :]\n",
    "\n",
    "model.display_prediction(img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Predict an image after rotating and flipping in some predefined ways and then average the predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_.X.shape, set_.Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_norm = model.predict(set_.X)\n",
    "pred_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict augmenting the image: 4 rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rot4 = model.predict_augmented(set_.X, n_rotations=4)\n",
    "pred_rot4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict augmenting the image: 8 rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rot8 = model.predict_augmented(set_.X, n_rotations=8)\n",
    "pred_rot8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** evaluate **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate both and compare the F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000,), (5000,), (5000,), (5000,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = set_.Y.flatten()\n",
    "pred_norm_class = predictions_to_class(pred_norm).flatten()\n",
    "pred_rot4_class = predictions_to_class(pred_rot4).flatten()\n",
    "pred_rot8_class = predictions_to_class(pred_rot8).flatten()\n",
    "pred_norm_class.shape, pred_rot4_class.shape, pred_rot8_class.shape, true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_norm_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_rot4_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_rot8_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_rot = rotate(im, 45, reshape=True, order=1, mode=\"reflect\")\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(im_rot)\n",
    "# plt.show()\n",
    "\n",
    "# pred = model.predict(np.array([im_rot]))[0]\n",
    "# pred = take_image_at_center(rotate_image(pred, -45), target_shape=(50, 50))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(prediction_to_class(pred), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the best threshold to classify a patch as road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91435875585854265, 0.65000000000000002)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_treshold(pred_norm[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.941424357353561, 0.65000000000000002)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_treshold(pred_rot4[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92609228256431197, 0.55000000000000004)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_treshold(pred_rot8[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "debugger = Pdb()\n",
    "debugger.set_trace() # put this line as a breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1, gen2 = image_generators(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models import batches_generator\n",
    "j = 0\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for x, y in batches_generator(X[:4], Y[:4], batch_size = 4):\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "    x_batches.append(x)\n",
    "    y_batches.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_batches).shape, np.array(y_batches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "if i >= x_batches[0].shape[0]:\n",
    "    i = 0\n",
    "    b += 1\n",
    "print(\"Batch\", str(b) + \". Image\", i)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches((20, 10))\n",
    "axs[0].imshow(x_batches[b][i], cmap='gray')\n",
    "axs[1].imshow(y_batches[b][i][:, :, 1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
