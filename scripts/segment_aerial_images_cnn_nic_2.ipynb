{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flow:\n",
    "1. load, reshape and split in test and train all the images\n",
    "2. instantiate a cnn model \n",
    "3. run the model on train and test data to verify how many epochs are more or less needed to get a nice model\n",
    "4. use that number of epochs to run cross validation (pass the whole 'set_' of images to the cross validation). Repeat from 2 with another model and compare.\n",
    "\n",
    "\n",
    "- If you notice that you hardly overfit maybe remove/decrease the dropout layers (e.g. from 0.25 to 0.15)\n",
    "- Try building a model that predicts directly 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing import *\n",
    "from cnn_models import *\n",
    "from datetime import datetime\n",
    "from evaluate import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "n = 70\n",
    "\n",
    "imgs, gt_imgs = load_images(n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "imgs, gt_imgs = imgs[i:i+1], gt_imgs[i:i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Reshape the data\n",
    "We reshape each input to fulfill our cnn inputs and output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! set predict_patch_width in accordance to the model you are using !!!\n",
    "# the shape of the output of the model depends on the strides parameters \n",
    "# (if a layer has stride=2 then each ouput's side is half of the input'side).\n",
    "# predict_patch_width must be equal to the total reduction of the model, e.g.\n",
    "# if the model has three layer with stride=2 => the input of the model is \n",
    "# reduced by a factor of 2*2*2=8, i.e. the ouptut will be patch-wise with \n",
    "# patches 8x8 pixels.\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "\n",
    "set_ = SimpleNamespace()\n",
    "set_.X = X\n",
    "set_.Y = Y\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generators(X, Y):\n",
    "    \"\"\" \n",
    "        Given the input images (X), their groundtruth (Y) returns two generators. \n",
    "        Both the generators return two images per time (respectively the input \n",
    "        image and the relative groundtruth). \n",
    "        Both the generators augment the images by randomly applying horizontal flip, \n",
    "        zoom (to improve prediction of wider and thinner roads) and filling the points \n",
    "        outside the boundaries by mirroring the images. \n",
    "        The two generators differ in the rotation: the first generator rotates the images\n",
    "        of degrees 90*k (where k=0,1,2,3), the second generator rotates the images \n",
    "        of any degree. \"\"\"\n",
    "    # TODO does it makes sense to shift (probably not)?\n",
    "    #     width_shift_range=0.1,\n",
    "    #     height_shift_range=0.1,\n",
    "    # TODO do we want to normalize the input? (requires the .fit call to compute mean and std)\n",
    "    # normalize with featurewise_center and featurewise_std_normalization\n",
    "    #     samplewise_center=True,\n",
    "    #     samplewise_std_normalization=True\n",
    "        # # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        # image_datagen.fit(X, augment=True, seed=seed)\n",
    "        # mask_datagen.fit(Y, augment=True, seed=seed)\n",
    "    \n",
    "    batch_size = 1 # take one image per time\n",
    "    Y = np.expand_dims(Y, axis=3) # \"wrap\" each pixel in a numpy array\n",
    "\n",
    "    ### 1. generator with rotations of 90*k \n",
    "    # use a seed so to apply the same transformation to both the input image (X) and the \n",
    "    # groundtruth (Y)\n",
    "    seed = 5\n",
    "    \n",
    "    data_gen_args = dict(    \n",
    "        zoom_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # combine generators into one which yields image and masks\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(Y, batch_size=batch_size, seed=seed)\n",
    "    \n",
    "    generator_no_rot = zip(image_generator, mask_generator)\n",
    "    \n",
    "    def generator_rot90k():\n",
    "#         print(\"entered generator_rot90k (should happen just one time)\")\n",
    "        # take the generator with no rotation and apply a rotation of 90*k\n",
    "        for x, y in generator_no_rot:\n",
    "            k = np.random.randint(4)\n",
    "            x_rot = np.rot90(x[0], k=k, axes=(0, 1))\n",
    "            y_rot = np.rot90(y[0], k=k, axes=(0, 1))\n",
    "            yield x_rot, y_rot\n",
    "    \n",
    "     ### 2. generator with any rotation\n",
    "    seed = 4\n",
    "    data_gen_args[\"rotation_range\"] = 360 # add the rotation parameter\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    # combine generators into one which yields image and masks\n",
    "    image_generator = image_datagen.flow(X, batch_size=batch_size, seed=seed)\n",
    "    mask_generator = mask_datagen.flow(Y, batch_size=batch_size, seed=seed)\n",
    "    generator_rot360_ = zip(image_generator, mask_generator)\n",
    "    \n",
    "    def generator_rot360():\n",
    "        # just change the shape of the output (instead of returning a batch\n",
    "        # with only one image retutn that image)\n",
    "        for x, y in generator_rot360_:\n",
    "            yield x[0], y[0]\n",
    "        \n",
    "    return generator_rot90k(), generator_rot360()\n",
    "\n",
    "def batches_generator(X, Y, batch_size=4):\n",
    "    \"\"\" Combine the two generators obtainef from image_generators to obtain \n",
    "        the batch generator used during training.\n",
    "        X, Y: input and output images\n",
    "        prob_gen1: probability of using gen1 to generate the next batch. \n",
    "        batch_size: number of images in each batch. \"\"\"\n",
    "    \n",
    "    gen1, gen2 = image_generators(X, Y) \n",
    "    prob_gen1 = 0.8\n",
    "    \n",
    "    x, y = next(gen1) # just to take the shape of x and y\n",
    "    while 1:\n",
    "        # generate the batch\n",
    "        batch_x = np.zeros((np.append(batch_size, x.shape))).astype('float32')\n",
    "        batch_y = np.zeros((np.append(batch_size, y.shape))).astype('float32')\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if np.random.rand()<prob_gen1:\n",
    "                # then use gen1\n",
    "                bx, by = next(gen1)\n",
    "#                 print(\"gen1: generated images: \", bx.shape, by.shape)\n",
    "                batch_x[i], batch_y[i] = bx, by\n",
    "            else:\n",
    "                bx, by = next(gen2)\n",
    "#                 print(\"gen2: generated images: \", bx.shape, by.shape)\n",
    "                batch_x[i], batch_y[i] = bx, by\n",
    "                \n",
    "#         print(\"Generated x and y batch of sizes: \", batch_x.shape, batch_y.shape, batch_y.dtype, batch_x.dtype)\n",
    "        yield batch_x, np_utils.to_categorical(batch_y, 2).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_x = []\n",
    "batches_y = []\n",
    "for i in range(10):\n",
    "    x_batch, y_batch = next(gen)\n",
    "    batches_x.append(x_batch)\n",
    "    batches_y.append(y_batch)\n",
    "batches_x = np.array(batches_x)\n",
    "batches_y = np.array(batches_y)\n",
    "\n",
    "# batches_x = np.expand_dims(batches_x, axis=0)\n",
    "# batches_y = np.expand_dims(batches_y, axis=0)\n",
    "batches_x.shape, batches_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = 0\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "img = set_.X[0]\n",
    "gt_img = set_.Y[0]\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "gt_img = predictions_to_img(gt_img, (h, w))\n",
    "new_img = make_img_overlay(img, gt_img)   \n",
    "axs[0][0].imshow(new_img)\n",
    "\n",
    "batch, im = 3, 0\n",
    "mg = batches_x[batch, im, :, :]\n",
    "gt_img = batches_y[batch, im, :, :, 0]\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "gt_img = predictions_to_img(gt_img, (h, w))\n",
    "new_img = make_img_overlay(img, gt_img)   \n",
    "axs[0][1].imshow(new_img)\n",
    "\n",
    "batch, im = 4, 0\n",
    "img = batches_x[batch, im, :, :]\n",
    "gt_img = batches_y[batch, im, :, :, 0]\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "gt_img = predictions_to_img(gt_img, (h, w))\n",
    "new_img = make_img_overlay(img, gt_img)   \n",
    "axs[1][0].imshow(new_img)\n",
    "\n",
    "batch, im = 5, 0\n",
    "img = batches_x[batch, im, :, :]\n",
    "gt_img = batches_y[batch, im, :, :, 0]\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "gt_img = predictions_to_img(gt_img, (h, w))\n",
    "new_img = make_img_overlay(img, gt_img)   \n",
    "axs[1][1].imshow(new_img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data_augmentation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.25\n",
    "\n",
    "train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape, train.Y.shape, test.X.shape, test.Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model or load a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose one of the models you defined (with model_n) and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an unique name for the model (so to avoid overwriting previous models)\n",
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H:%M:%S}'.format(datetime.now()))\n",
    "model_path = \"models/\"+folder_name\n",
    "model = CnnModel(model_n=8, model_path=model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otherwise load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the folder\n",
    "folder_name = \"model_2017-12-16_140054\"\n",
    "model_path = \"../models/\"+folder_name\n",
    "models = []\n",
    "models_id = range(1, 6)\n",
    "for i in range(len(models_id)):\n",
    "    models.append(CnnModel(model_n=models_id[i], model_path=model_path))\n",
    "    models[i].load() # load the model and its weights\n",
    "    models[i].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Train the model on the train data while validating it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a batch size which is a factor of train.shape[0] so that all the batches are fo the same size\n",
    "num_epochs=1\n",
    "batch_size=1\n",
    "_ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Run cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.cross_validation(set_, batch_size=batch_size, num_epochs=num_epochs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histories of the cross validation\n",
    "plot_history(result[\"history_mean\"]) \n",
    "# history of the folds (check if there is a worst case)\n",
    "# plot_history(result[\"histories\"][0]) \n",
    "# plot_history(result[\"histories\"][1]) \n",
    "# plot_history(result[\"histories\"][2]) \n",
    "# plot_history(result[\"histories\"][3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "last_epochs=1000 # plot only the last n epochs\n",
    "for model in models:\n",
    "    print(model.name())\n",
    "    model.plot_history(last_epochs=last_epochs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are all the layers \n",
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = set_.X[0]\n",
    "layer_num = 1\n",
    "\n",
    "model.show_layer_output(image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "set_ = set_\n",
    "\n",
    "for model in models:\n",
    "    print(model.name())\n",
    "    model.evaluate_model(set_.X, set_.Y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "img = test.X[0][:, :]\n",
    "\n",
    "model.display_prediction(img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Predict an image after rotating and flipping in some predefined ways and then average the predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_.X.shape, set_.Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_norm = model.predict(set_.X)\n",
    "pred_norm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict augmenting the image: 4 rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rot4 = model.predict_augmented(set_.X, n_rotations=4)\n",
    "pred_rot4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict augmenting the image: 8 rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rot8 = model.predict_augmented(set_.X, n_rotations=8)\n",
    "pred_rot8.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ** evaluate **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate both and compare the F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = set_.Y.flatten()\n",
    "pred_norm_class = predictions_to_class(pred_norm).flatten()\n",
    "pred_rot4_class = predictions_to_class(pred_rot4).flatten()\n",
    "pred_rot8_class = predictions_to_class(pred_rot8).flatten()\n",
    "pred_norm_class.shape, pred_rot4_class.shape, pred_rot8_class.shape, true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_norm_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_rot4_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_predictions(pred_rot8_class, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_rot = rotate(im, 45, reshape=True, order=1, mode=\"reflect\")\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(im_rot)\n",
    "# plt.show()\n",
    "\n",
    "# pred = model.predict(np.array([im_rot]))[0]\n",
    "# pred = take_image_at_center(rotate_image(pred, -45), target_shape=(50, 50))\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(prediction_to_class(pred), cmap=\"gray\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose the best threshold to classify a patch as road."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_treshold(pred_norm[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_treshold(pred_rot4[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_treshold(pred_rot8[:, :, :, 1].flatten(), true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "debugger = Pdb()\n",
    "debugger.set_trace() # put this line as a breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1, gen2 = image_generators(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models import batches_generator\n",
    "j = 0\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for x, y in batches_generator(X[:4], Y[:4], batch_size = 4):\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "    x_batches.append(x)\n",
    "    y_batches.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(x_batches).shape, np.array(y_batches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0\n",
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i += 1\n",
    "if i >= x_batches[0].shape[0]:\n",
    "    i = 0\n",
    "    b += 1\n",
    "print(\"Batch\", str(b) + \". Image\", i)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches((20, 10))\n",
    "axs[0].imshow(x_batches[b][i], cmap='gray')\n",
    "axs[1].imshow(y_batches[b][i][:, :, 1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
