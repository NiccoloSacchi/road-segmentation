{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flow:\n",
    "1. load, reshape and split in test and train all the images\n",
    "2. instantiate a cnn model \n",
    "3. run the model on train and test data to verify how many epochs are more or less needed to get a nice model\n",
    "4. use that number of epochs to run cross validation (pass the whole 'set_' of images to the cross validation). Repeat from 2 with another model and compare.\n",
    "\n",
    "\n",
    "- If you notice that you hardly overfit maybe remove/decrease the dropout layers (e.g. from 0.25 to 0.15)\n",
    "- Try building a model that predicts directly 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# keras functions\n",
    "from keras import callbacks\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# our libraries\n",
    "from preprocessing import *\n",
    "\n",
    "from cnn_models import *\n",
    "from evaluate import *\n",
    "\n",
    "import scipy as scipy\n",
    "from mask_to_submission import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "n = 100\n",
    "\n",
    "imgs, gt_imgs = load_images(n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Reshape the data\n",
    "We reshape each input to fulfill our cnn inputs and output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !!! set predict_patch_width in accordance to the model you are using !!!\n",
    "# the shape of the output of the model depends on the strides parameters \n",
    "# (if a layer has stride=2 then each ouput's side is half of the input'side).\n",
    "# predict_patch_width must be equal to the total reduction of the model, e.g.\n",
    "# if the model has three layer with stride=2 => the input of the model is \n",
    "# reduced by a factor of 2*2*2=8, i.e. the ouptut will be patch-wise with \n",
    "# patches 8x8 pixels.\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "\n",
    "set_ = SimpleNamespace()\n",
    "set_.X = X\n",
    "set_.Y = Y\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.04\n",
    "\n",
    "train, test = split_train_test(imgs, gt_imgs, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape,train.Y.shape,test.X.shape,test.Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model or load a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose one of the models you defined (with model_n) and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate an unique name for the model (so to avoid overwriting previous models)\n",
    "from cnn_models import *\n",
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H%M%S}'.format(datetime.now()))\n",
    "model_path = \"..\\\\models\\\\\"+folder_name\n",
    "model = CnnModel(model_n=7, model_path=model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otherwise load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# give the folder\n",
    "folder_name = \"model_2017-12-17_015606\"\n",
    "model_path = \"..\\models\\\\\"+folder_name\n",
    "model = CnnModel(model_n = 7,model_path=model_path)\n",
    "model.load() # load the model and its weights\n",
    "model.load_weights(\"2017-12-19_152321_best-weightsmodel_leakyrelu_maxpooling.hdf5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Train the model on the train data while validating it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass a batch size which is a factor of train.shape[0] so that all the batches are fo the same size\n",
    "from cnn_models import *\n",
    "\n",
    "num_epochs=100\n",
    "batch_size=4\n",
    "_ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.plot_history(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Run cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "batch_size=3\n",
    "result = model.cross_validation(set_, batch_size=batch_size, num_epochs=num_epochs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the histories of the cross validation\n",
    "plot_history(result[\"history_mean\"]) \n",
    "# history of the folds (check if there is a worst case)\n",
    "# plot_history(result[\"histories\"][0]) \n",
    "# plot_history(result[\"histories\"][1]) \n",
    "# plot_history(result[\"histories\"][2]) \n",
    "# plot_history(result[\"histories\"][3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_epochs=20 # plot only the last n epochs\n",
    "model.plot_history(last_epochs=last_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are all the layers \n",
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = test.X[0]\n",
    "layer_num = 8\n",
    "\n",
    "model.show_layer_output(image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re-evaluate on some subset\n",
    "test_ratio = 0.04\n",
    "train, test = split_train_test(imgs, gt_imgs, test_ratio=test_ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "\n",
    "\n",
    "set_ = test\n",
    "\n",
    "model.evaluate_model(set_.X, set_.Y)\n",
    "set_.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and reset the train set as full dataset\n",
    "test_ratio = 0.04\n",
    "train, test = split_train_test(imgs, gt_imgs, test_ratio=test_ratio, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "for i in range(10):\n",
    "    img = train.X[50+i][:, :]\n",
    "    model.display_prediction(img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39000000000000001"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rot4 = model.predict_augmented(set_.X, n_rotations=4)\n",
    "true = predictions_to_class(np.array([gt_img_to_Y(y, predict_patch_width=8) for y in set_.Y])).flatten()\n",
    "_,threshold = grid_search_treshold(pred_rot4[:, :, :, 1].flatten(), true)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.39\n",
      "Loading 5 images to predict\n",
      "loading image ../dataset/test_set_images/test_1/test_1.png\n",
      "loading image ../dataset/test_set_images/test_2/test_2.png\n",
      "loading image ../dataset/test_set_images/test_3/test_3.png\n",
      "loading image ../dataset/test_set_images/test_4/test_4.png\n",
      "loading image ../dataset/test_set_images/test_5/test_5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\imageio\\core\\util.py:78: UserWarning: Lossy conversion from float64 to uint8, range [0, 1]\n",
      "  dtype_str, out_type.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5 images to predict\n",
      "loading image ../dataset/test_set_images/test_6/test_6.png\n",
      "loading image ../dataset/test_set_images/test_7/test_7.png\n",
      "loading image ../dataset/test_set_images/test_8/test_8.png\n",
      "loading image ../dataset/test_set_images/test_9/test_9.png\n",
      "loading image ../dataset/test_set_images/test_10/test_10.png\n",
      "Loading 5 images to predict\n",
      "loading image ../dataset/test_set_images/test_11/test_11.png\n",
      "loading image ../dataset/test_set_images/test_12/test_12.png\n",
      "loading image ../dataset/test_set_images/test_13/test_13.png\n",
      "loading image ../dataset/test_set_images/test_14/test_14.png\n",
      "loading image ../dataset/test_set_images/test_15/test_15.png\n",
      "Loading 5 images to predict\n",
      "loading image ../dataset/test_set_images/test_16/test_16.png\n",
      "loading image ../dataset/test_set_images/test_17/test_17.png\n",
      "loading image ../dataset/test_set_images/test_18/test_18.png\n",
      "loading image ../dataset/test_set_images/test_19/test_19.png\n",
      "loading image ../dataset/test_set_images/test_20/test_20.png\n"
     ]
    }
   ],
   "source": [
    "from cnn_models import *\n",
    "model.predict_augmented_and_export(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple models testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H%M%S}'.format(datetime.now()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cnn_models import *\n",
    "#models = [\n",
    "#0          model1,\n",
    "#1          model2,\n",
    "#2          additional_conv_layer_model,\n",
    "#3          max_pooling_model,\n",
    "#4          leaky_relu_model,\n",
    "#5          decreased_dropout_model,\n",
    "#6          many_filters_model, \n",
    "#7          model_leakyrelu_maxpooling, \n",
    "#8          model_relu_maxpooling] \n",
    "models_to_train =  [7]\n",
    "for i in models_to_train:\n",
    "    # generate an unique name for the model (so to avoid overwriting previous models)\n",
    "    model_path = \"..\\\\models\\\\\"+folder_name\n",
    "    model = CnnModel(model_n=i, model_path=model_path)\n",
    "    model.summary()\n",
    "    num_epochs=3\n",
    "    batch_size=2\n",
    "    _ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') \n",
    "    model.save()\n",
    "    model.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "debugger = Pdb()\n",
    "debugger.set_trace() # put this line as a breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen1, gen2 = image_generators(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cnn_models import batches_generator\n",
    "j = 0\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for x, y in batches_generator(X[:4], Y[:4], batch_size = 4):\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "    x_batches.append(x)\n",
    "    y_batches.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(x_batches).shape, np.array(y_batches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "if i >= x_batches[0].shape[0]:\n",
    "    i = 0\n",
    "    b += 1\n",
    "print(\"Batch\", str(b) + \". Image\", i)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches((20, 10))\n",
    "axs[0].imshow(x_batches[b][i], cmap='gray')\n",
    "axs[1].imshow(y_batches[b][i][:, :, 1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
