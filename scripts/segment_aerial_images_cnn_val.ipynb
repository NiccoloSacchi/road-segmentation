{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flow:\n",
    "1. load, reshape and split in test and train all the images\n",
    "2. instantiate a cnn model \n",
    "3. run the model on train and test data to verify how many epochs are more or less needed to get a nice model\n",
    "4. use that number of epochs to run cross validation (pass the whole 'set_' of images to the cross validation). Repeat from 2 with another model and compare.\n",
    "\n",
    "\n",
    "- If you notice that you hardly overfit maybe remove/decrease the dropout layers (e.g. from 0.25 to 0.15)\n",
    "- Try building a model that predicts directly 16x16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# keras functions\n",
    "from keras import callbacks\n",
    "from keras import preprocessing\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# our libraries\n",
    "from preprocessing import *\n",
    "\n",
    "from cnn_models import *\n",
    "from evaluate import *\n",
    "\n",
    "import scipy as scipy\n",
    "from mask_to_submission import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "The goal here is to use the CNN to reduce the size of the input image to obtain a \"discretized\" image of shape, e.g. (W/16, H/16). Every entry of this image is related to a patch in the input image. This obtained image is compared by the CNN with the groundtruth (after properly discretizing by it patch-wise)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loaded a set of images\n",
    "n = 10\n",
    "\n",
    "imgs, gt_imgs = load_images(n)\n",
    "imgs[0].shape, gt_imgs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Reshape the data\n",
    "We reshape each input to fulfill our cnn inputs and output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !!! set predict_patch_width in accordance to the model you are using !!!\n",
    "# the shape of the output of the model depends on the strides parameters \n",
    "# (if a layer has stride=2 then each ouput's side is half of the input'side).\n",
    "# predict_patch_width must be equal to the total reduction of the model, e.g.\n",
    "# if the model has three layer with stride=2 => the input of the model is \n",
    "# reduced by a factor of 2*2*2=8, i.e. the ouptut will be patch-wise with \n",
    "# patches 8x8 pixels.\n",
    "predict_patch_width = 8\n",
    "\n",
    "X, Y = images_to_XY(imgs, gt_imgs, predict_patch_width=predict_patch_width)\n",
    "\n",
    "set_ = SimpleNamespace()\n",
    "set_.X = X\n",
    "set_.Y = Y\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - For now avoid cross validation, just split the datasest in test and train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_ratio = 0.25\n",
    "\n",
    "train, test = split_train_test(X, Y, test_ratio=test_ratio, seed=1)\n",
    "train.X.shape, train.Y.shape, test.X.shape, test.Y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # check it makes sense (show the i-th input of set_)\n",
    "# i = 0\n",
    "# set_ = test\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# axs[0].imshow(set_.Y[i, :, :, 1], cmap='gray')\n",
    "# axs[1].imshow(set_.X[i, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Build the CNN model or load a previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose one of the models you defined (with model_n) and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate an unique name for the model (so to avoid overwriting previous models)\n",
    "folder_name = \"model_\"+str('{0:%Y-%m-%d_%H%M%S}'.format(datetime.now()))\n",
    "model_path = \"..\\\\models\\\\\"+folder_name\n",
    "model = CnnModel(model_n=0, model_path=model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otherwise load a previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# give the folder\n",
    "folder_name = \"model_2017-12-12_184955\"\n",
    "model_path = \"..\\models\\\\\"+folder_name\n",
    "model = CnnModel(model_path=model_path)\n",
    "model.load() # load the model and its weights\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Train the model on the train data while validating it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pass a batch size which is a factor of train.shape[0] so that all the batches are fo the same size\n",
    "num_epochs=1000\n",
    "batch_size=3\n",
    "_ = model.train(train, test=test, num_epochs=num_epochs, batch_size=batch_size, monitor='val_loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Run cross validation to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_epochs=10\n",
    "batch_size=3\n",
    "result = model.cross_validation(set_, batch_size=batch_size, num_epochs=num_epochs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the histories of the cross validation\n",
    "plot_history(result[\"history_mean\"]) \n",
    "# history of the folds (check if there is a worst case)\n",
    "# plot_history(result[\"histories\"][0]) \n",
    "# plot_history(result[\"histories\"][1]) \n",
    "# plot_history(result[\"histories\"][2]) \n",
    "# plot_history(result[\"histories\"][3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the accuracy and the loss obtained during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_epochs=20 # plot only the last n epochs\n",
    "model.plot_history(last_epochs=last_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the output of a specific layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are all the layers \n",
    "model.model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose a layer and an image \n",
    "image = test.X[0]\n",
    "layer_num = 8\n",
    "\n",
    "model.show_layer_output(image, layer_num, filename=\"\") # pass a filename if you want to store the image to file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the performance on train or test\n",
    "set_ = test\n",
    "\n",
    "model.evaluate_model(set_.X, set_.Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose an image to predict (or part of it)\n",
    "img = train.X[5][:, :]\n",
    "\n",
    "model.display_prediction(img, ax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_and_export(model):\n",
    "    filename_list = []\n",
    "    for batch_idx in range(10):\n",
    "        images = load_images_to_predict(batch_idx*5,batch_idx*5+5)\n",
    "        predictions = model.predict(images)\n",
    "        img_matrix = np.zeros([predictions.shape[0],predictions.shape[1],predictions.shape[2]])\n",
    "        \n",
    "        print(img_matrix.shape)\n",
    "        for i in range(predictions.shape[0]):\n",
    "            for row in range(predictions.shape[1]):\n",
    "                for col in range (predictions.shape[2]):\n",
    "                    if predictions[i][row][col][0] < predictions[i][row][col][1] :\n",
    "                        img_matrix[i][row][col] = 1\n",
    "            img_idx = batch_idx*5+i+1\n",
    "            filename = \"../dataset/test_set_images/test_\"+str(img_idx)+\"/gt\"+str(img_idx)+\".jpg\"\n",
    "            imageio.imwrite(filename, img_matrix[i])\n",
    "            filename_list.append(filename)\n",
    "            \n",
    "    masks_to_submission(\"testsub.csv\",filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5 images to predict\n",
      "loading image ../dataset/test_set_images/test_1/test_1.png\n",
      "loading image ../dataset/test_set_images/test_2/test_2.png\n",
      "loading image ../dataset/test_set_images/test_3/test_3.png\n",
      "loading image ../dataset/test_set_images/test_4/test_4.png\n",
      "loading image ../dataset/test_set_images/test_5/test_5.png\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2e0d0a03242e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcnn_models\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_and_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Val\\Desktop\\road-segmentation\\scripts\\cnn_models.py\u001b[0m in \u001b[0;36mpredict_and_export\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_images_to_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mimg_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from cnn_models import *\n",
    "model.predict_and_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "images = load_images_to_predict(5)\n",
    "predictions = model.predict(images)\n",
    "images.shape,predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def export_predictions(predictions):\n",
    "    img_matrix = np.zeros([predictions.shape[0],predictions.shape[1],predictions.shape[2]])\n",
    "    print(img_matrix.shape)\n",
    "    for i in range(predictions.shape[0]):\n",
    "        for row in range(predictions.shape[1]):\n",
    "            for col in range (predictions.shape[2]):\n",
    "                if predictions[i][row][col][0] < predictions[i][row][col][1] :\n",
    "                    img_matrix[i][row][col] = 1\n",
    "        \n",
    "        imageio.imwrite(\"../dataset/test_set_images/test_\"+str(i+1)+\"/gt\"+str(i+1)+\".jpg\", img_matrix[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "export_predictions(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mask_to_submission import *\n",
    "filename_list = []\n",
    "filename_list.append(\"gt1.jpg\")\n",
    "filename_list.append(\"gt2.jpg\")\n",
    "filename_list.append(\"gt3.jpg\")\n",
    "masks_to_submission(\"testsub.csv\",filename_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Save/load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some callbacks example: \n",
    "\n",
    "# create a list of callbacks we want to use during training\n",
    "# # a callback to store epoch results to a csv file\n",
    "# filename='model_train_new.csv'\n",
    "# csv_log = callbacks.CSVLogger(filename, separator=',', append=False)\n",
    "\n",
    "# # a callback to stob before doing the predefined number of epochs (stop before overfitting the data)\n",
    "# early_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='min')\n",
    "\n",
    "# # a callback to save the best model (best model = the one with the lowest 'monitor' variable)\n",
    "# filepath = \"best-weights-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
    "# checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # callbacks_list = [csv_log,early_stopping,checkpoint]\n",
    "\n",
    "print(\n",
    "    \"-get configurations:\", \"\\n\",\n",
    "    model.get_config(), \"\\n\",\n",
    "    model.layers[0].get_config(), \"\\n\",\n",
    "\n",
    "    \"\\n-get shapes\", \"\\n\",\n",
    "    model.layers[0].input_shape, \"\\n\",\n",
    "    model.layers[0].output_shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-get weights\", \"\\n\",\n",
    "    model.layers[0].get_weights()[0].shape, \"\\n\",\n",
    "    \n",
    "    \"\\n-check if trainable\", \"\\n\",\n",
    "    model.layers[0].trainable, \"\\n\", # you can set this to false to \"freeze\" a layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Pdb\n",
    "debugger = Pdb()\n",
    "debugger.set_trace() # put this line as a breakpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen1, gen2 = image_generators(X, Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cnn_models import batches_generator\n",
    "j = 0\n",
    "x_batches = []\n",
    "y_batches = []\n",
    "\n",
    "for x, y in batches_generator(X[:4], Y[:4], batch_size = 4):\n",
    "    j += 1\n",
    "    if j > 10:\n",
    "        break\n",
    "    x_batches.append(x)\n",
    "    y_batches.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(x_batches).shape, np.array(y_batches).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i += 1\n",
    "if i >= x_batches[0].shape[0]:\n",
    "    i = 0\n",
    "    b += 1\n",
    "print(\"Batch\", str(b) + \". Image\", i)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches((20, 10))\n",
    "axs[0].imshow(x_batches[b][i], cmap='gray')\n",
    "axs[1].imshow(y_batches[b][i][:, :, 1], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
