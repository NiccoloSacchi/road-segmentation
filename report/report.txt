Abstract 
The goal of this project is to segment satellite images in order to discriminate the roads from the background. Several approaches have been tried in the past, most of them required a lot of preprocessing and did not gained great performances. Invented in the late 20th century, the convolutional neural networs (CNNs) only recently were succesfully applied to images classification problems and performed considerably better than other techniques. 
The model we used in this project consists of a CNN whose input can be an image of any size and the output is the respective groundtruth. Among other techiques, on-fly data augmentation have been used to improve the training and also reduce overfitting. Moreover, we applied two simple but effective techniques to improve the predictions. We will also show that, according to our tests, our model outperforms the considered baselines. 

-Introduction
The segmentation problem can be defined as the problem of assigning a class label to a set of pixels so to classify the part(s) of an image. 
The goal of this project is to segment the roads in 50 satellite images so to extract the mask of the roads. The metric used to evaluate the prediction of the roads is the F1 score {put formula}.  
In recent years, thanks the increase in computing performance and the possibility to exploit GPUs to parallelize computation, CNNs outperformed most of the techniques in solving different tasks, e.g. image classification, image segmentation, natural language processing, handwriting generation, automatic game playing and many others. The strenghts of the CNNs derives from a hierachy of filters which are learnt during the training. Thanks to these filters, the CNNs are capable of producing more and more comples features, i.e. high level representation of the input, as the image goes deeper in the network. However, a drawback of CNNs is the need of a large, fully-labelled dataset. This drawback can be compensated with data augmentation. 
In the following sections we will give an overview of the techniques we tried focusing in particular to the CNN we implemented and tuned. Section II explains ..., Section III ...

-Exploratory data analisys 
We are given two sets of images acquired from GoogleMaps: (1) a train set composed by RGB images of size 400x400 pixels, each one of them is provided with its ground-truth image of the same size where white pixels represent roads and black pixels represent the background, (2) a test set composed by RGB images 608x608 pixels whose ground-truth has to be produced. 
The aim of the project is to label patches of 16x16 pixels, therefore, depending on the model used, pixels of the ground-truth had to be grouped and averaged so to provide the class label for that patch. We adopted a reshold of 0.25, if the average of the pixels in a patch was above the treshold then that pach was labelled ad road, otherwise it was labelled as background.
By taking a look at the train set we could notice the problem had its nontrivialities, e.g. parking lots non labelled as roads, trees, shadows, buildings and cars covering the surface of the roads and roofs of the same color of the roads, as can be seen in Figure A ("here we cover the background to show that in some corner cases roads are covered by (a) buildings, (b) highways, (d) trees and we also show the ambiguity of parking lots in (e)"). Those problems can be solved only if we consider also the neighborhood of each patch to correctly classify it. That task can be achieved with feature extraction, either manually, with complex and advanced techniques, or automatically with the CNNs.  

-Models and Methods
The first techniques we studied involved feature extraction using interesing, still complex and not very efficient techniques that fails in more extreme cases, e.g. when there are object obtructing the view of the road or there is a change of brightness through different images. Such techniques involved for example computation of the gradient at each pixel (so to exploit the fact that roads have continuity in one direction), the use of an edge detection algorithm to extract the boundaries of the objetcs and the use of vector graphics to represent images with geometrical primitives such as points, lines, curves, and shapes or polygons [cite CNNs learn general features]. Given the complexity of those solutions and poorness of the results when compared to the CNNs, we opted for the latter which are well know for the little preprocessing needed and great efficiency in solving these kind of tasks.
We started from three very simple baselines: (1) a model that predicts all as road (notice that, since the metric chosen is the F1 score computen the road predictions, a model that predicts all as background would have higher accuracy but an F1 score of zero), (2-3) we considereed each 16x16 patch as an input and for each one of them we produced 6 simple features extracted from the mean and the standard deviation of each RGB channel in the patch, the obtained dataset has been used to train a logistic regression and a random forest. The F1 scores of these three baselines is shown in Figure B. As expected, this analisys shows that those methods fails in this complex task if more advaced feture extraction is not in place.
Therefore we  what regards CNNs, there are two main approaches: (1) design a CNN which direclty segment the input image and outputs the mask for theroads [cite Lis], (2) reduce the segmentation problem to classifying each patch, i.e. build a CNN that given as input a patch with its context (neighborhood of that patch) labels that patch as either road or background [cite dario]. We tried both the techniques but then opted and focused on (1) since it required almost no preprocoessing and showed better results. 

A. CNN design
Our CNN takes as input an image of any size and outputs the estimated probability of being a road for each patch of that image. We tried both predicting 8x8 patch-wise and 16x16 patch-wise and observed better results when predictin KxK patch-wise. The structure of our CNN is depicted in Figure D. Sice we had problems with the memory of the GPU, we adopded convolutional layers of increasing number of filters so that the first layers whould have bigger inputs but less filters and the last layers would have smaller inputs but more filters (note that the output of a convolutional layer, when strides is 1x1 and padding is used, is H x W x #filters where H x W is the size of the input). After the convolutional layer we use the leaky relu as activation function since we experieced problemd od dead filter with the relu activaion filters, see Figure H. We used k max pooling layers with a pool size of 2x2 where 2^k is the size of the patch we wanted to predict, e.g. to predict 8x8 patch-wise we adopted 3 max pooling layers so to reduce the size of the input image by a factor of 8 on each side. Note that increasing the strides of the convolutional layer would lead to the same size reduction but we opted for max pooling so to automatically select the higher activations. Dropout... 

B. Data augmentation
We rotate and flip the images...

C. Cross validation

-Final results

-Conclusions


